{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 국민청원 텍스트 분류 프로젝트"
      ],
      "metadata": {
        "id": "61sIqnyXwBH1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01. 데이터 다운로드 및 패키지 설치"
      ],
      "metadata": {
        "id": "h9lnkA8ywGVr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "h-qPZjnpv6Er",
        "outputId": "9bd09651-e39c-41df-ba9f-9eece09730ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.1)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.5.0 konlpy-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sNJkpBXJwPOk",
        "outputId": "cad39788-5d08-4f2b-a13b-df19592b9475"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.66.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.32.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.4.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.26.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (0.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n",
            "Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchtext\n",
            "Successfully installed torchtext-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ7rchoDwZH2",
        "outputId": "03e92b5f-4a01-4376-850b-e609cbef010b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vydXUa0FwlIx",
        "outputId": "3957409a-2b72-4b77-e0db-c9c156a6dd2e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/AIsystem4weeks/crawling.zip\" -d \"/content/drive/MyDrive/Colab Notebooks/AIsystem4weeks/dataset/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ygV5YnmcxF1E",
        "outputId": "9f7a6a39-7a70-4767-b1c6-89280c34b653"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Colab Notebooks/AIsystem4weeks/crawling.zip\n",
            "  inflating: /content/drive/MyDrive/Colab Notebooks/AIsystem4weeks/dataset/crawling.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "rycfX5BtxZ2_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/AIsystem4weeks/dataset/crawling.csv\")"
      ],
      "metadata": {
        "id": "ZHDV24G8EK0H"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[0].content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "iwroVufyFIYs",
        "outputId": "58e419fc-69f2-4abc-85d4-f5983a84bddb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'본인은 2019년 8월 경 서울지방병무청 제1검사장 탈의실에서 믿을 수 없는 것을 발견하였다. 탈의실 천장에 CCTV를 발견한 것이다. 본인은 이에 경악하였다.\\r\\n\\r\\r\\n탈의실에 CCTV를 설치하는 것은 개인정보보호법 25조 2항을 위반한 사안으로 심각한 법적 문제이다. 촬영이 되었다면 이는 성폭력범죄의 처벌 등에 관한 특례법 14조 1항 위반이기도 하다. 또한, 법적인 문제일 뿐만 아니라 개인의 자유를 침해하고 성적 수치심을 불러일으키는 매우 심각한 윤리적 문제이다.\\r\\r\\n이렇듯 불법카메라는 그 자체로 굉장히 심각한 문제이다. 그런데 공공기관에서 탈의실에 불법, 비윤리적으로 카메라를 설치하였고, 이를 운영하였을지도 모르는 상황이 발생하였다. 도대체 한국 정부는 인권을 무엇이라고 생각하는 것인가? \\r\\n\\r\\r\\n발견 직후 인권위에 진정을 넣었지만 인권위에서는 현재까지 조사가 되고 있는지, 진행은 어떻게 되었는지 어떠한 답변도 하지 않고 있다. 병무청측에서도 어떠한 답변도 없었다.\\r\\n\\r\\r\\n더 이상 답변을 기다리는 것이 의미 없다고 생각한 본인은 모 커뮤니티에 이 사실을 알렸다. 이후 이슈화가 되자 병무청은 설치는 되었으나 운영은 하지 않았다는 대답을 내놓았지만 이에 대한 조사 경과 발표나 사과, 책임 있는 대응은 전혀 보여주고 있지 않다.\\r\\n\\r\\r\\n이는 개인의 자유와 권리의 본질적 내용을 침해하는 강제징집, 국제노동기구가 인정한 강제징용/강제노동을 당하는 20대 남성들이 국가에 의해 신체를 감시당한 사건이다. 한국 정부는 병역의무자에게는 인권이 없다고 생각하는가?\\r\\n\\r\\r\\n언제까지 국가는 개인들을 노예 취급할 것인가? 몇백원도 안되는 시급을 주며 강제로 폭력 속에서 부리는 것도 모자라 이제는 이런 어처구니 없는 일까지 일어나는 것에 경악하지 않을 수 없다. \\r\\n\\r\\r\\n이에 본인은 위 사실을 강력히 규탄하며 아래와 같은 대응을 요구한다.\\r\\n\\r\\r\\n1. 서울지방병무청 징병검사소 탈의실에 CCTV가 설치된 경위와 운영 여부, 관리 내역 등에 대해 낱낱이 조사하여 그 진상을 밝혀라.\\r\\r\\n2. 병무청장과 서울지방병무청장은 이 사건에 책임을 지고 사퇴하라. 자진사퇴를 거부한다면 정부는 이들을 파면하라.\\r\\r\\n3. 이 사건과 관련된 책임자와 담당자를 처벌하라.\\r\\r\\n4. 병무정장 명의의 사과문을 병무청 사이트를 비롯한 온라인과 전국의 신체검사소에 올려 신체검사대상들이 그 사과 내용을 알게하고, 사과내용과 조사 경과를 언론에 배포하라.\\r\\r\\n5. 어떠한 이유에서 인권위가 위 민원을 무시하고 태만하였는지 조사하고 책임자를 문책하라.\\r\\r\\n6. 병무청이 CCTV 제보자와 민원인들을 보복하지 않도록 감시하고 제보자와 민원인을 적극적으로 보호하라.\\r\\r\\n7. 한국 정부는 20대 남성의 강제징집과 강제노동에 대해 최저임금 3배 이상의 시급을 지급하고 빠른 시일내로 현재의 징병제를 개혁하여 강제징집과 강제징용, 강제노동을 폐지하라. 또한 지금까지 강제적으로 끌려가 피해를 당한 당사자들에게 사과하고 합당한 피해보상금을 제공하라.\\r\\n\\r\\n\\r\\r\\n각주 1. 개인정보보호법 제25조 2항\\r\\r\\n제25조(영상정보처리기기의 설치ㆍ운영 제한) \\r\\r\\n② 누구든지 불특정 다수가 이용하는 목욕실, 화장실, 발한실(發汗室), 탈의실 등 개인의 사생활을 현저히 침해할 우려가 있는 장소의 내부를 볼 수 있도록 영상정보처리기기를 설치ㆍ운영하여서는 아니 된다. 다만, 교도소, 정신보건 시설 등 법령에 근거하여 사람을 구금하거나 보호하는 시설로서 대통령령으로 정하는 시설에 대하여는 그러하지 아니하다.\\r\\n\\r\\r\\n각주2. 개인정보보호법 제75조(과태료) 1항 3호\\r\\r\\n다음 각 호의 어느 하나에 해당하는 자에게는 5천만원 이하의 과태료를 부과한다. \\r\\r\\n3. 제25조제2항을 위반하여 영상정보처리기기를 설치ㆍ운영한 자\\r\\n\\r\\r\\n각주3. 성폭력범죄의 처벌 등에 관한 특례법 제14조(카메라 등을 이용한 촬영) 1항 \\r\\r\\n카메라나 그 밖에 이와 유사한 기능을 갖춘 기계장치를 이용하여 성적 욕망 또는 수치심을 유발할 수 있는 사람의 신체를 촬영대상자의 의사에 반하여 촬영한 자는 5년 이하의 징역 또는 3천만원 이하의 벌금에 처한다.  <개정 2018. 12. 18.>\\r\\n\\r\\r\\n각주4. 국제노동기구 제29호 강제근로 협약, 제105호 강제근로 폐지 협약\\r\\r\\n제105호 \\r\\r\\n(가) 정치적 견해 또는 기존 정치 사회 경제제도에 사상적으로 반대하는 견해를 가지거나 발표하는 것에 대한 제재 및 정치적 억압 또는 교육의 수단\\r\\r\\n(나) 경제발전을 목적으로 노동력을 동원 이용하는 경우\\r\\r\\n(다) 노동 규제의 수단\\r\\r\\n(라) 파업참가에 대한 제재\\r\\r\\n(마) 인종적 사회적 민족적 또는 종교적 차별대우의 수단'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_white_space(text):\n",
        "    text = re.sub(r'[\\t\\r\\n\\f\\v]', ' ', str(text))\n",
        "    return text\n",
        "\n",
        "def remove_special_char(text):\n",
        "    text = re.sub('[^ ㄱ-ㅣ가-힣 0-9]+', ' ', str(text))\n",
        "    return text\n",
        "\n",
        "df.title = df.title.apply(remove_white_space)\n",
        "df.title = df.title.apply(remove_special_char)\n",
        "\n",
        "df.content = df.content.apply(remove_white_space)\n",
        "df.content = df.content.apply(remove_special_char)"
      ],
      "metadata": {
        "id": "j4Wm5349FMGw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[3].content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "2RTy3t5OFkEH",
        "outputId": "4248c6c5-79fd-4742-eea6-5265700ab6a1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'미세먼지의 심각성은 이제 적극적인 대안을 요구 하고 있습니다    우리 일상에서 가장 쉽고 적극적으로 할 수 있는 것은 모든 건축물 외부에 스프링쿨러를 설치하는 것입니다     도로변에도 가로등 등을 이용하여 스프링쿨러를 설치하여 일정 농도이상의 미세먼지 발생시 물을 뿌리면 즉시 미세먼지를 흡착 줄일 수 있습니다    특히 옥상조경 혹은 건물외부 수직정원 등과 결합한다면 환경문제를 적극적으로 해결할 수 있습니다    더운 여름에는 10도이상의 온도를 낮출 수 있고   겨울에는 미세먼지 뿐만아니라 도시의 온도를 10도 이상 올릴 수도 있습니다    그리고 각 가정마다 각 건물마다 수도 시설이 갖추어져 옥외 스프링쿨러 설치 비용은 최소 몇만원 최대로 하더라도 100만원을 넘지 않는 저예산이지만 효과는 즉시 나타날 수 있습니다    옥상녹화화 수직정원이 결합된다면 금수강산의 대한민국을 다시 만들 수 있습니다    감사합니다    참고로 저는 농업인이며 농생물학 원예생태시스템공학을 전공 박사학위 소유자 이며 현제 수직정원과 인공구조물 녹화 그리고 식물신품종 개발로 해외 로열티를 수출하고 있으며 정원관련분야의 일도하고 있습니다    미세먼지와 도시 환경문제의 근본적 대책은 매우 많은 시간과 노력이 필요한 것 입니다만 우선 적극적임 대안 중 가장 실효성있는 대안 이니 적극 검토 바랍니다 '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Tokenizer 생성"
      ],
      "metadata": {
        "id": "rRyjGRKDGFV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "okt = Okt()"
      ],
      "metadata": {
        "id": "DUY8RH-vFpo5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "okt.morphs(df.loc[3].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "foG9p3LxGN5t",
        "outputId": "ed5be14b-4b6b-48ba-fe30-bb10c2088b63"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['미세먼지',\n",
              " '의',\n",
              " '심각',\n",
              " '성은',\n",
              " '이제',\n",
              " '적극',\n",
              " '적',\n",
              " '인',\n",
              " '대안',\n",
              " '을',\n",
              " '요구',\n",
              " '하고',\n",
              " '있습니다',\n",
              " '우리',\n",
              " '일상',\n",
              " '에서',\n",
              " '가장',\n",
              " '쉽고',\n",
              " '적극',\n",
              " '적',\n",
              " '으로',\n",
              " '할',\n",
              " '수',\n",
              " '있는',\n",
              " '것',\n",
              " '은',\n",
              " '모든',\n",
              " '건축물',\n",
              " '외부',\n",
              " '에',\n",
              " '스프링',\n",
              " '쿨러',\n",
              " '를',\n",
              " '설치',\n",
              " '하는',\n",
              " '것',\n",
              " '입니다',\n",
              " '도로',\n",
              " '변',\n",
              " '에도',\n",
              " '가로등',\n",
              " '등',\n",
              " '을',\n",
              " '이용',\n",
              " '하여',\n",
              " '스프링',\n",
              " '쿨러',\n",
              " '를',\n",
              " '설치',\n",
              " '하여',\n",
              " '일정',\n",
              " '농도',\n",
              " '이상',\n",
              " '의',\n",
              " '미세먼지',\n",
              " '발생',\n",
              " '시',\n",
              " '물',\n",
              " '을',\n",
              " '뿌리',\n",
              " '면',\n",
              " '즉시',\n",
              " '미세먼지',\n",
              " '를',\n",
              " '흡착',\n",
              " '줄일',\n",
              " '수',\n",
              " '있습니다',\n",
              " '특히',\n",
              " '옥상',\n",
              " '조경',\n",
              " '혹은',\n",
              " '건물',\n",
              " '외부',\n",
              " '수직',\n",
              " '정원',\n",
              " '등',\n",
              " '과',\n",
              " '결합',\n",
              " '한',\n",
              " '다',\n",
              " '면',\n",
              " '환경문제',\n",
              " '를',\n",
              " '적극',\n",
              " '적',\n",
              " '으로',\n",
              " '해결',\n",
              " '할',\n",
              " '수',\n",
              " '있습니다',\n",
              " '더운',\n",
              " '여름',\n",
              " '에는',\n",
              " '10',\n",
              " '도',\n",
              " '이상',\n",
              " '의',\n",
              " '온도',\n",
              " '를',\n",
              " '낮출',\n",
              " '수',\n",
              " '있고',\n",
              " '겨울',\n",
              " '에는',\n",
              " '미세먼지',\n",
              " '뿐',\n",
              " '만',\n",
              " '아니라',\n",
              " '도시',\n",
              " '의',\n",
              " '온도',\n",
              " '를',\n",
              " '10',\n",
              " '도',\n",
              " '이상',\n",
              " '올릴',\n",
              " '수도',\n",
              " '있습니다',\n",
              " '그리고',\n",
              " '각',\n",
              " '가정',\n",
              " '마다',\n",
              " '각',\n",
              " '건물',\n",
              " '마다',\n",
              " '수도',\n",
              " '시설',\n",
              " '이',\n",
              " '갖추어져',\n",
              " '옥외',\n",
              " '스프링',\n",
              " '쿨러',\n",
              " '설치',\n",
              " '비용',\n",
              " '은',\n",
              " '최소',\n",
              " '몇',\n",
              " '만원',\n",
              " '최대로',\n",
              " '하더라도',\n",
              " '100만원',\n",
              " '을',\n",
              " '넘지',\n",
              " '않는',\n",
              " '저',\n",
              " '예산',\n",
              " '이지만',\n",
              " '효과',\n",
              " '는',\n",
              " '즉시',\n",
              " '나타날',\n",
              " '수',\n",
              " '있습니다',\n",
              " '옥상녹화',\n",
              " '화',\n",
              " '수직',\n",
              " '정원',\n",
              " '이',\n",
              " '결합',\n",
              " '된다면',\n",
              " '금수강산',\n",
              " '의',\n",
              " '대한민국',\n",
              " '을',\n",
              " '다시',\n",
              " '만들',\n",
              " '수',\n",
              " '있습니다',\n",
              " '감사합니다',\n",
              " '참고',\n",
              " '로',\n",
              " '저',\n",
              " '는',\n",
              " '농업인',\n",
              " '이며',\n",
              " '농',\n",
              " '생물학',\n",
              " '원',\n",
              " '예',\n",
              " '생태',\n",
              " '시스템',\n",
              " '공학',\n",
              " '을',\n",
              " '전공',\n",
              " '박사학위',\n",
              " '소유자',\n",
              " '이며',\n",
              " '현',\n",
              " '제',\n",
              " '수직',\n",
              " '정원',\n",
              " '과',\n",
              " '인공',\n",
              " '구',\n",
              " '조물',\n",
              " '녹화',\n",
              " '그리고',\n",
              " '식물',\n",
              " '신',\n",
              " '품종',\n",
              " '개발',\n",
              " '로',\n",
              " '해외',\n",
              " '로열티',\n",
              " '를',\n",
              " '수출',\n",
              " '하고',\n",
              " '있으며',\n",
              " '정원',\n",
              " '관련',\n",
              " '분야',\n",
              " '의',\n",
              " '일도',\n",
              " '하고',\n",
              " '있습니다',\n",
              " '미세먼지',\n",
              " '와',\n",
              " '도시',\n",
              " '환경문제',\n",
              " '의',\n",
              " '근본',\n",
              " '적',\n",
              " '대책',\n",
              " '은',\n",
              " '매우',\n",
              " '많은',\n",
              " '시간',\n",
              " '과',\n",
              " '노력',\n",
              " '이',\n",
              " '필요한',\n",
              " '것',\n",
              " '입니다만',\n",
              " '우선',\n",
              " '적극',\n",
              " '적임',\n",
              " '대안',\n",
              " '중',\n",
              " '가장',\n",
              " '실효',\n",
              " '성',\n",
              " '있는',\n",
              " '대안',\n",
              " '이니',\n",
              " '적극',\n",
              " '검토',\n",
              " '바랍니다']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"title_token\"] = df.title.apply(okt.morphs)"
      ],
      "metadata": {
        "id": "kS-uclvEGT81"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"content_token\"] = df.content.apply(okt.morphs)"
      ],
      "metadata": {
        "id": "WCRk3SpbGn3i"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['count'] = df['count'].replace({',' : ''}, regex = True).apply(lambda x : int(x))"
      ],
      "metadata": {
        "id": "ZiT9pfBpLC2l"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"label\"] = df[\"count\"].apply(lambda x: \"Yes\" if int(x) > 1000 else \"No\")"
      ],
      "metadata": {
        "id": "AtLL-1pwGvUY"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"token_final\"] = df.title_token + df.content_token"
      ],
      "metadata": {
        "id": "aht6ItLwHQ2g"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"/content/drive/MyDrive/Colab Notebooks/AIsystem4weeks/dataset/df.csv\", index=False, encoding=\"utf-8-sig\")"
      ],
      "metadata": {
        "id": "MRhxfK8XHlqS"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/AIsystem4weeks/dataset/df.csv\")"
      ],
      "metadata": {
        "id": "zSBwxaJkIHZJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 단어 벡터 학습"
      ],
      "metadata": {
        "id": "rv0XGSKnJyIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "24zAZD8iIQ49"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_drop = df[[\"token_final\", \"label\"]]"
      ],
      "metadata": {
        "id": "NJJ0PEE1NLbP"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = Word2Vec(df_drop['token_final'],\n",
        "                           sg = 1, # skip-gram\n",
        "                           vector_size = 100,\n",
        "                           window = 2,\n",
        "                           min_count = 1,\n",
        "                           workers = 4\n",
        "                           )\n"
      ],
      "metadata": {
        "id": "7OhD8hLMIhwZ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model.wv.most_similar(\"음주운전\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oAuEP6pXMHZ3",
        "outputId": "bd44bbcb-2762-44c3-9788-265f70251f1c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('음주', 0.8254624009132385),\n",
              " ('뺑소니', 0.7772663235664368),\n",
              " ('가정폭력', 0.75697922706604),\n",
              " ('무면허', 0.752689778804779),\n",
              " ('동물학대', 0.731476366519928),\n",
              " ('강력범죄', 0.7251717448234558),\n",
              " ('경미한', 0.7231563329696655),\n",
              " ('스토킹', 0.7143633961677551),\n",
              " ('범의', 0.7114167213439941),\n",
              " ('촉법소년', 0.7090577483177185)]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model.wv.save_word2vec_format(\"/content/drive/MyDrive/Colab Notebooks/AIsystem4weeks/dataset/word2vec_100\")"
      ],
      "metadata": {
        "id": "_zh7bVuHJNVM"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5. 학습데이터 분리 및 전처리"
      ],
      "metadata": {
        "id": "d7wqfXHhJ1Dp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import RandomState\n",
        "\n",
        "rng = RandomState()\n",
        "\n",
        "tr = df_drop.sample(frac=0.8, random_state=rng)\n",
        "val = df_drop.loc[~df_drop.index.isin(tr.index)]\n",
        "\n",
        "tr.to_csv('/content/drive/MyDrive/Colab Notebooks/AIsystem4weeks/dataset/train.csv', index=False, encoding='utf-8-sig')\n",
        "val.to_csv('/content/drive/MyDrive/Colab Notebooks/AIsystem4weeks/dataset/validation.csv', index=False, encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "wXiPUCOaJ4tF"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data import Field, TabularDataset, BucketIterator"
      ],
      "metadata": {
        "id": "5k-rrfFhKXHF"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def tokenizer(text):\n",
        "  text = re.sub('[\\[\\]\\']', '', str(text))\n",
        "  text = text.split(', ')\n",
        "  return text\n",
        "\n",
        "\n",
        "TEXT = Field(tokenize=tokenizer)\n",
        "LABEL = Field(sequential=False)"
      ],
      "metadata": {
        "id": "0EyE9StpKoGk"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, validation = TabularDataset.splits(\n",
        "    path = '/content/drive/MyDrive/Colab Notebooks/AIsystem4weeks/dataset/',\n",
        "    train = 'train.csv',\n",
        "    validation = 'validation.csv',\n",
        "    format = 'csv',\n",
        "    fields = [('text', TEXT), ('label', LABEL)],\n",
        "    skip_header = True\n",
        ")"
      ],
      "metadata": {
        "id": "CxsfapSANg8F"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import Vectors"
      ],
      "metadata": {
        "id": "gY9w9sfrPX0S"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors = Vectors(name=\"/content/drive/MyDrive/Colab Notebooks/AIsystem4weeks/dataset/word2vec_100\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6Und2OcPrkp",
        "outputId": "7a5256fc-958b-42ab-9ed7-361ce474dee7"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/115919 [00:00<?, ?it/s]WARNING:torchtext.vocab:Skipping token b'115919' with 1-dimensional vector [b'100']; likely a header\n",
            "100%|██████████| 115919/115919 [00:05<00:00, 20539.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectors.get_vecs_by_tokens([\"음주운전\", \"경찰\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mvxecRR6PzH_",
        "outputId": "d2090dba-bbf2-40ce-e2ee-701e4f0158e3"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-3.0596e-02,  5.8809e-02,  1.0217e-01, -4.1449e-01, -4.8435e-01,\n",
              "          5.4148e-02, -1.5849e-01,  1.4152e+00,  3.5276e-01, -3.3121e-01,\n",
              "         -1.3515e-01, -7.0695e-01, -5.0184e-01,  1.2130e-01,  7.0898e-02,\n",
              "         -2.9134e-01, -1.5452e-01,  2.4210e-02, -3.4748e-03, -6.9410e-01,\n",
              "         -3.0257e-03, -6.7591e-01,  8.5639e-01, -2.7614e-01, -4.8158e-01,\n",
              "          4.3820e-02, -2.6797e-01, -4.2378e-03, -5.0938e-01, -2.0197e-01,\n",
              "          3.5371e-01,  1.1296e-05,  2.1175e-01, -1.2008e-01,  2.6784e-01,\n",
              "          2.1964e-01, -8.6971e-02,  4.9958e-01, -2.6111e-01, -5.0778e-01,\n",
              "          5.6902e-01, -7.8566e-01,  1.0733e-01,  2.0490e-01, -1.4446e-01,\n",
              "         -1.0831e-01,  5.0617e-01,  8.3595e-02,  1.2499e-01,  4.9239e-01,\n",
              "          5.2657e-01, -2.4698e-01,  2.1540e-01, -2.4402e-01, -3.6921e-01,\n",
              "          2.8699e-01, -3.9311e-01,  1.1659e-01, -2.5250e-01,  3.3678e-02,\n",
              "          1.0127e-01, -3.1566e-02,  2.1445e-01,  1.6711e-01,  1.8432e-01,\n",
              "          4.5654e-01, -3.6160e-01,  5.4282e-03, -7.7463e-01,  2.7411e-01,\n",
              "          6.7784e-02, -1.6606e-02,  2.6225e-01,  2.2826e-02,  8.2831e-01,\n",
              "         -6.1447e-02,  1.9257e-01, -4.2231e-03, -1.6748e-01,  2.0340e-01,\n",
              "         -1.6309e-01, -7.9067e-01,  8.8377e-02, -1.7584e-02,  9.0890e-02,\n",
              "          7.4421e-02, -9.4061e-02, -9.0790e-02,  4.7879e-01,  1.3953e-01,\n",
              "          4.6533e-01, -2.4630e-01,  1.4722e-01,  1.1752e-01,  8.3014e-01,\n",
              "          3.7232e-01,  3.1862e-01, -3.6377e-02,  7.3285e-01, -5.9431e-01],\n",
              "        [-1.0195e-01, -1.0051e-01,  8.0386e-02, -9.3849e-02,  4.6407e-02,\n",
              "         -1.0827e-01, -2.7488e-01,  9.6002e-01,  3.7583e-01, -3.7616e-01,\n",
              "         -7.0243e-02,  1.4463e-01,  2.4559e-01,  1.9015e-01, -4.7480e-01,\n",
              "         -5.5879e-01, -8.7793e-02, -8.5006e-03, -1.2054e-01, -7.3225e-01,\n",
              "          1.1134e-01, -2.5454e-01,  6.8013e-01, -4.1680e-01, -1.9570e-01,\n",
              "          3.0172e-02, -2.3295e-01, -1.4425e-02, -5.8337e-01, -1.9110e-01,\n",
              "          7.8331e-01, -9.1401e-02,  1.9640e-01, -6.0243e-01, -1.1134e-01,\n",
              "         -1.1234e-01, -3.2220e-02, -6.3377e-02,  1.2554e-01,  6.5386e-03,\n",
              "         -4.0753e-01, -8.7912e-01, -1.1796e-01,  7.8087e-01,  5.7815e-02,\n",
              "         -3.1763e-01, -8.7810e-02, -3.3049e-02, -2.0969e-01,  2.8496e-01,\n",
              "          1.2432e-01, -1.0796e-01,  1.8154e-02, -5.5845e-01, -5.7261e-01,\n",
              "          6.5702e-01,  6.0769e-01,  1.8017e-01,  1.4875e-01,  3.6674e-01,\n",
              "         -7.2426e-01, -6.1144e-01,  2.1363e-01,  1.1368e-01, -7.6139e-02,\n",
              "         -3.2183e-01,  1.2585e-01,  2.3656e-01, -7.9741e-01,  3.7184e-01,\n",
              "          5.1415e-03,  7.2465e-01,  7.5288e-01,  9.1942e-02,  5.2754e-01,\n",
              "          1.6130e-01,  5.9906e-01,  3.6236e-01, -1.1860e-01, -1.7117e-01,\n",
              "          7.4879e-01, -2.8933e-01, -5.9350e-01,  4.7126e-01,  1.8608e-03,\n",
              "         -1.3906e-01,  4.6721e-01,  4.6204e-01,  2.2203e-01, -6.3805e-03,\n",
              "          5.5932e-01,  8.2883e-02, -3.2496e-01, -1.4142e-01,  5.8022e-01,\n",
              "          5.5996e-01, -1.4592e-01, -5.7423e-02,  4.2328e-01, -1.9649e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.build_vocab(train, vectors = vectors, min_freq = 1, max_size = None)\n",
        "LABEL.build_vocab(train)"
      ],
      "metadata": {
        "id": "GJhQzWFjPSTd"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "7Q1L348xQevt"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = TEXT.vocab\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_iter, validation_iter = BucketIterator.splits(\n",
        "    datasets = (train, validation),\n",
        "    batch_size = 8,\n",
        "    device = device,\n",
        "    sort = False\n",
        ")\n",
        "\n",
        "print('임베딩 벡터의 개수와 차원 : {} '.format(TEXT.vocab.vectors.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dwb7buBOoOx",
        "outputId": "77329925-5655-45da-d741-4592d1f3db96"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "임베딩 벡터의 개수와 차원 : torch.Size([104034, 100]) \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 모델 구현"
      ],
      "metadata": {
        "id": "yXyYs0GvQyH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "ZwR4lqCNQkDP"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed = nn.Embedding(len(TEXT.vocab), 100)"
      ],
      "metadata": {
        "id": "IGew_QOYRADP"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embed)\n",
        "print(embed.weight[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix2t1rqfRJlY",
        "outputId": "2d76a83a-3103-4982-bc97-a5834ed1034a"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding(104034, 100)\n",
            "tensor([ 1.3509,  0.3045, -0.7341, -0.7933,  1.9243, -1.0441, -0.0917, -0.1500,\n",
            "        -1.9778,  0.1743, -1.2043, -1.0877,  1.3057,  0.7750, -0.5772,  0.2646,\n",
            "        -0.9794, -0.3104, -1.2105, -1.4194,  0.8624, -1.1075, -0.5825,  0.6018,\n",
            "         1.5183, -1.6114, -2.0476,  0.5182, -0.2402,  0.4167,  1.1656, -0.6891,\n",
            "        -1.0914,  0.3510,  0.3698, -0.5992, -2.3133,  0.3248,  0.5144,  0.5214,\n",
            "         1.0274,  0.3741, -0.5552, -0.8392,  1.2387,  0.2794, -0.2842, -0.4919,\n",
            "         1.2812, -1.2471,  0.4673,  0.1814,  0.7056, -1.0924, -0.3298,  0.1920,\n",
            "         0.9029, -0.3833,  1.1108,  0.2403, -1.9957,  0.3415,  0.3656,  0.6358,\n",
            "         1.8032, -0.4181, -2.4623,  1.5435,  0.1219, -0.2196,  0.1111, -0.4748,\n",
            "        -0.5690,  0.4775,  1.0909,  0.2224,  0.0575,  0.0960,  0.6253, -1.4551,\n",
            "        -0.3264,  0.4419,  0.7499, -0.0381, -1.0664, -2.5035,  1.3299, -1.0836,\n",
            "        -0.6953,  0.8625,  0.0165,  1.6797,  1.6554,  0.5479, -0.9214,  1.3186,\n",
            "        -0.3880,  1.6479, -1.3241,  0.8423], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed.weight.data.copy_(TEXT.vocab.vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWGqkLX6RI_z",
        "outputId": "bce9bbe3-db25-4fb2-a654-bcfa86ca0d3d"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.2237,  0.0882, -0.0217,  ..., -0.3458, -0.1756, -0.0120],\n",
              "        ...,\n",
              "        [-0.1848,  0.0219,  0.0629,  ..., -0.1272,  0.0245,  0.0274],\n",
              "        [-0.0649, -0.0121,  0.0216,  ..., -0.0696, -0.0070,  0.0285],\n",
              "        [-0.0536,  0.0065,  0.0472,  ..., -0.0387,  0.0218,  0.0392]])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embed.weight[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GHvFOVOR2Om",
        "outputId": "d00ee186-d6cd-49ec-d23d-ee05983ad9ee"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.2237,  0.0882, -0.0217,  0.3620, -0.1883, -0.5353,  0.2950,  0.2727,\n",
            "        -0.3858, -0.0290,  0.3661, -0.2263, -0.2031,  0.4768, -0.4138,  0.1610,\n",
            "         0.1333, -0.0555, -0.5223, -0.7141,  0.2828, -0.0300,  0.2580, -0.8550,\n",
            "         0.3206,  0.1159, -0.2475,  0.6952, -0.7007,  0.4251, -0.2368, -0.0618,\n",
            "         0.1098, -0.5300,  0.1946, -0.1865,  0.2140, -0.0113,  0.0546, -0.3591,\n",
            "        -0.4690, -0.3867, -0.3845,  0.0550, -0.1183,  0.3102, -0.2602, -0.0485,\n",
            "         0.0821,  0.5667,  0.0355,  0.3349, -0.1392, -0.4816,  0.4625,  0.2882,\n",
            "        -0.0167,  0.4206,  0.0899, -0.0100,  0.2468, -0.0123, -0.1678, -0.4487,\n",
            "        -0.2854,  0.1727, -0.5750,  0.2016, -0.0531,  0.9929,  0.3119,  0.7118,\n",
            "        -0.0320, -0.0949,  1.2920, -0.3011,  0.4981, -0.0450, -0.0760, -0.5450,\n",
            "        -0.4805, -0.1739,  0.4140,  0.8735, -0.2054,  0.0183,  0.3496, -0.2620,\n",
            "         0.0677,  0.6475, -0.2792, -0.6427, -0.0098,  0.1152,  0.3429,  0.0333,\n",
            "         0.0735, -0.3458, -0.1756, -0.0120], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv1 = nn.Conv2d(in_channels = 1,\n",
        "          out_channels = 10,\n",
        "          kernel_size = (3, 100))"
      ],
      "metadata": {
        "id": "JtB9PJa4SXx2"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_iter:\n",
        "  #print(batch.text)\n",
        "  #print(batch.text.size())\n",
        "  text, target = batch.text, batch.label\n",
        "  text = text.to(device)\n",
        "  target = target.to(device)\n",
        "  print(text)\n",
        "  print(target)\n",
        "  embed = embed.to(device)\n",
        "  embed_text = embed(text)\n",
        "  print(embed_text.size())\n",
        "  #embed_text = embed_text.view(8,-1, 100)\n",
        "  #print(embed_text.size())\n",
        "  embed_text = embed_text.unsqueeze(1)\n",
        "  print(embed_text.size())\n",
        "  conv1 = conv1.to(device)\n",
        "  conv1(embed_text)\n",
        "  #embed_text = embed_text.unsqueeze(1)\n",
        "  #print(embed_text.size())\n",
        "\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVKhZD8-Twnn",
        "outputId": "0d2c3eaf-3566-403c-a049-f3c7af6bba20"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   53,    10,   102,  ..., 13162,   346,  5286],\n",
            "        [    5,   596,     9,  ...,     5,  1679,     4],\n",
            "        [  235, 11368,  1260,  ..., 12277,  1911,  2078],\n",
            "        ...,\n",
            "        [    1,   200,     1,  ...,     1,     1,     1],\n",
            "        [    1,   225,     1,  ...,     1,     1,     1],\n",
            "        [    1,    76,     1,  ...,     1,     1,     1]], device='cuda:0')\n",
            "tensor([2, 1, 2, 2, 1, 1, 2, 2], device='cuda:0')\n",
            "torch.Size([896, 8, 100])\n",
            "torch.Size([896, 1, 8, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv1(embed(torch.tensor([2, 3])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "bBCMQErVTb8E",
        "outputId": "e95429d3-165d-4760-fe3e-11d343c508d5"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [2, 100]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-63915cda9786>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 454\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    455\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [2, 100]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZjW68w0rTkl_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}