{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOek7VQHGJ63fHx40RJfRY2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":126,"metadata":{"id":"JCHyVHxzpVYf","executionInfo":{"status":"ok","timestamp":1697618253497,"user_tz":-540,"elapsed":2,"user":{"displayName":"원인호","userId":"14809865194257546197"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from math import sqrt\n","import torch.nn.functional as F"]},{"cell_type":"markdown","source":["# Encoder"],"metadata":{"id":"h7SnuvsCq-XU"}},{"cell_type":"code","source":["class Configuration():\n","  dim_token_emb= 768\n","  attention_probs_dropout_prob= 0.1\n","  classifier_dropout= None\n","  gradient_checkpointing= False\n","  hidden_act= \"gelu\"\n","  hidden_dropout_prob= 0.1\n","  hidden_size= 768\n","  initializer_range= 0.02\n","  intermediate_size= 3072\n","  layer_norm_eps= 1e-12\n","  max_position_embeddings= 512\n","  model_type= \"encoder\"\n","  num_attention_heads= 12\n","  num_hidden_layers= 12\n","  pad_token_id= 0\n","  position_embedding_type= \"absolute\"\n","  type_vocab_size= 2\n","  use_cache= True\n","  vocab_size= 30522"],"metadata":{"id":"F6vvpppEpbB0","executionInfo":{"status":"ok","timestamp":1697618250848,"user_tz":-540,"elapsed":1082,"user":{"displayName":"원인호","userId":"14809865194257546197"}}},"execution_count":106,"outputs":[]},{"cell_type":"code","source":["config = Configuration()"],"metadata":{"id":"iCpooMrgpfSD","executionInfo":{"status":"ok","timestamp":1697618252274,"user_tz":-540,"elapsed":14,"user":{"displayName":"원인호","userId":"14809865194257546197"}}},"execution_count":107,"outputs":[]},{"cell_type":"code","source":["config.dim_token_emb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"txmPITv0pfxO","executionInfo":{"status":"ok","timestamp":1697618252275,"user_tz":-540,"elapsed":14,"user":{"displayName":"원인호","userId":"14809865194257546197"}},"outputId":"8d4859c7-28d6-400c-decc-68cfdc04c38a"},"execution_count":108,"outputs":[{"output_type":"execute_result","data":{"text/plain":["768"]},"metadata":{},"execution_count":108}]},{"cell_type":"code","source":["def scaled_dot_product_attention(query, key, value):\n","  dim_k = key.size(1)\n","  score_matrix = torch.bmm(query, key.transpose(1, 2)) / sqrt(dim_k)\n","  weight = F.softmax(score_matrix, dim=-1)\n","  return torch.bmm(weight, value)"],"metadata":{"id":"uVz-NfkspisE","executionInfo":{"status":"ok","timestamp":1697618252275,"user_tz":-540,"elapsed":10,"user":{"displayName":"원인호","userId":"14809865194257546197"}}},"execution_count":109,"outputs":[]},{"cell_type":"code","source":["class AttentionHead(nn.Module):\n","    def __init__(self, embed_dim, head_dim):\n","        super().__init__()\n","        self.q = nn.Linear(embed_dim, head_dim)\n","        self.k = nn.Linear(embed_dim, head_dim)\n","        self.v = nn.Linear(embed_dim, head_dim)\n","\n","    def forward(self, hidden_state):\n","        attn_outputs = scaled_dot_product_attention(\n","            self.q(hidden_state), self.k(hidden_state), self.v(hidden_state))\n","        return attn_outputs"],"metadata":{"id":"PmdamVFwqC1s","executionInfo":{"status":"ok","timestamp":1697618252275,"user_tz":-540,"elapsed":10,"user":{"displayName":"원인호","userId":"14809865194257546197"}}},"execution_count":110,"outputs":[]},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        embed_dim = config.hidden_size\n","        num_heads = config.num_attention_heads\n","        head_dim = embed_dim // num_heads\n","        self.heads = nn.ModuleList(\n","            [AttentionHead(embed_dim, head_dim) for _ in range(num_heads)]\n","        )\n","        self.output_linear = nn.Linear(embed_dim, embed_dim)\n","\n","    def forward(self, hidden_state):\n","        x = torch.cat([h(hidden_state) for h in self.heads], dim=-1)\n","        x = self.output_linear(x)\n","        return x"],"metadata":{"id":"fykfd8n2qUIh","executionInfo":{"status":"ok","timestamp":1697618252275,"user_tz":-540,"elapsed":10,"user":{"displayName":"원인호","userId":"14809865194257546197"}}},"execution_count":111,"outputs":[]},{"cell_type":"code","source":["class FeedForward(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.linear_1 = nn.Linear(config.hidden_size, config.intermediate_size)\n","        self.linear_2 = nn.Linear(config.intermediate_size, config.hidden_size)\n","        self.gelu = nn.GELU()\n","        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","\n","    def forward(self, x):\n","        x = self.linear_1(x)\n","        x = self.gelu(x)\n","        x = self.linear_2(x)\n","        x = self.dropout(x)\n","        return x"],"metadata":{"id":"MiT7lDTZqWM_","executionInfo":{"status":"ok","timestamp":1697618252275,"user_tz":-540,"elapsed":10,"user":{"displayName":"원인호","userId":"14809865194257546197"}}},"execution_count":112,"outputs":[]},{"cell_type":"code","source":["class TransformerEncoderLayer(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.layer_norm_1 = nn.LayerNorm(config.hidden_size)\n","        self.layer_norm_2 = nn.LayerNorm(config.hidden_size)\n","        self.attention = MultiHeadAttention(config)\n","        self.feed_forward = FeedForward(config)\n","\n","    def forward(self, x):\n","        # Apply layer normalization and then copy input into query, key, value\n","        hidden_state = self.layer_norm_1(x)\n","        # Apply attention with a skip connection\n","        x = x + self.attention(hidden_state)\n","        # Apply feed-forward layer with a skip connection\n","        x = x + self.feed_forward(self.layer_norm_2(x))\n","        return x"],"metadata":{"id":"u5Y_vBacqewB","executionInfo":{"status":"ok","timestamp":1697618252275,"user_tz":-540,"elapsed":10,"user":{"displayName":"원인호","userId":"14809865194257546197"}}},"execution_count":113,"outputs":[]},{"cell_type":"code","source":["encoder_layer = TransformerEncoderLayer(config)"],"metadata":{"id":"MhPJ6n_7qkkW","executionInfo":{"status":"ok","timestamp":1697618252275,"user_tz":-540,"elapsed":9,"user":{"displayName":"원인호","userId":"14809865194257546197"}}},"execution_count":114,"outputs":[]},{"cell_type":"code","source":["class Embeddings(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.token_embeddings = nn.Embedding(config.vocab_size,\n","                                             config.hidden_size)\n","        self.position_embeddings = nn.Embedding(config.max_position_embeddings,\n","                                                config.hidden_size)\n","        self.layer_norm = nn.LayerNorm(config.hidden_size, eps=1e-12)\n","        self.dropout = nn.Dropout()\n","\n","    def forward(self, input_ids):\n","        # Create position IDs for input sequence\n","        seq_length = input_ids.size(1)\n","        position_ids = torch.arange(seq_length, dtype=torch.long).unsqueeze(0)\n","        # Create token and position embeddings\n","        token_embeddings = self.token_embeddings(input_ids)\n","        position_embeddings = self.position_embeddings(position_ids)\n","        # Combine token and position embeddings\n","        embeddings = token_embeddings + position_embeddings\n","        embeddings = self.layer_norm(embeddings)\n","        embeddings = self.dropout(embeddings)\n","        return embeddings"],"metadata":{"id":"n5uWeZx_qrn3","executionInfo":{"status":"ok","timestamp":1697618252275,"user_tz":-540,"elapsed":9,"user":{"displayName":"원인호","userId":"14809865194257546197"}}},"execution_count":115,"outputs":[]},{"cell_type":"code","source":["class TransformerEncoder(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.embeddings = Embeddings(config)\n","        self.layers = nn.ModuleList([TransformerEncoderLayer(config)\n","                                     for _ in range(config.num_hidden_layers)])\n","\n","    def forward(self, x):\n","        x = self.embeddings(x)\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x"],"metadata":{"id":"F9TpitPSqtAz","executionInfo":{"status":"ok","timestamp":1697618252275,"user_tz":-540,"elapsed":9,"user":{"displayName":"원인호","userId":"14809865194257546197"}}},"execution_count":116,"outputs":[]},{"cell_type":"code","source":["encoder = TransformerEncoder(config)"],"metadata":{"id":"ruPiPjfEqvH0","executionInfo":{"status":"ok","timestamp":1697618252275,"user_tz":-540,"elapsed":9,"user":{"displayName":"원인호","userId":"14809865194257546197"}}},"execution_count":117,"outputs":[]},{"cell_type":"markdown","source":["# Decoder"],"metadata":{"id":"3KFyUJ3nq8Ah"}},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BJZfO1ttq9BM","executionInfo":{"status":"ok","timestamp":1697618252275,"user_tz":-540,"elapsed":8,"user":{"displayName":"원인호","userId":"14809865194257546197"}},"outputId":"98a92895-12d7-48e1-a1cb-d6ad1d61e523"},"execution_count":118,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["y = torch.LongTensor([[0, 1, 2, 3, 4, 5], [3, 4, 5, 6, 7, 8]])\n","y.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gJsfG0yGrGg6","executionInfo":{"status":"ok","timestamp":1697618252275,"user_tz":-540,"elapsed":6,"user":{"displayName":"원인호","userId":"14809865194257546197"}},"outputId":"7b7fa5b5-59fa-4e6a-94eb-b50d9cdc713e"},"execution_count":119,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 6])"]},"metadata":{},"execution_count":119}]},{"cell_type":"code","source":["def scaled_dot_product_attention(query, key, value, mask=None) :\n","  dim_k = key.size(1)\n","  score_matrix = torch.bmm(query, key.transpose(1, 2)) / sqrt(dim_k)\n","  if mask is not None :\n","    score_matrix = score_matrix.masked_fill(mask==0, float('-inf'))\n","  weight = F.softmax(score_matrix, dim=-1)\n","  return torch.bmm(weight, value)"],"metadata":{"id":"H0zjpdROrPlH","executionInfo":{"status":"ok","timestamp":1697618252275,"user_tz":-540,"elapsed":4,"user":{"displayName":"원인호","userId":"14809865194257546197"}}},"execution_count":120,"outputs":[]},{"cell_type":"code","source":["class DecoderEmbeddings(nn.Module):\n","  def __init__(self, config):\n","    super().__init__()\n","    self.token_embedding = nn.Embedding(config.vocab_size, config.hidden_size)\n","    self.position_embedding = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n","    self.layer_norm = nn.LayerNorm(config.hidden_size, eps=1e-12)\n","    self.dropout = nn.Dropout()\n","\n","  def forward(self, input_ids):\n","    # Create position IDs for input sequence\n","    seq_length = input_ids.size(1)\n","    position_ids = torch.arange(seq_length, dtype=torch.int).unsqueeze(0)\n","    # Create token and position embeddings\n","    token_embeddings = self.token_embedding(input_ids)\n","    position_embeddings = self.position_embedding(position_ids)\n","    # Combine token and position embeddings\n","    embeddings = token_embeddings + position_embeddings\n","    embeddings = self.layer_norm(embeddings)\n","    embeddings = self.dropout(embeddings)\n","    return embeddings"],"metadata":{"id":"g49RCPf1sDzh","executionInfo":{"status":"ok","timestamp":1697618252276,"user_tz":-540,"elapsed":5,"user":{"displayName":"원인호","userId":"14809865194257546197"}}},"execution_count":121,"outputs":[]},{"cell_type":"code","source":["embedding_layer = DecoderEmbeddings(config)\n","embeddings = embedding_layer(y)\n","embeddings.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2e-WBiuKvr5Y","executionInfo":{"status":"ok","timestamp":1697618253497,"user_tz":-540,"elapsed":1226,"user":{"displayName":"원인호","userId":"14809865194257546197"}},"outputId":"d4d500f5-f48f-4563-dfe7-788b7bd56235"},"execution_count":122,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 6, 768])"]},"metadata":{},"execution_count":122}]},{"cell_type":"code","source":["class MaskedAttentionHead(nn.Module):\n","  def __init__(self, embedding_dim, head_dim):\n","    super().__init__()\n","    self.q = nn.Linear(embedding_dim, head_dim)\n","    self.k = nn.Linear(embedding_dim, head_dim)\n","    self.v = nn.Linear(embedding_dim, head_dim)\n","\n","  def forward(self, hidden_state):\n","    query = self.q(hidden_state)\n","    key = self.k(hidden_state)\n","    value = self.v(hidden_state)\n","    mask_ = torch.tril(torch.ones(query.size(1), query.size(1), dtype=torch.int)).unsqueeze(0)\n","    attn_outputs = scaled_dot_product_attention(query, key, value, mask=mask_)\n","    return attn_outputs"],"metadata":{"id":"I_2S0IrxwoXq","executionInfo":{"status":"ok","timestamp":1697618253497,"user_tz":-540,"elapsed":4,"user":{"displayName":"원인호","userId":"14809865194257546197"}}},"execution_count":123,"outputs":[]},{"cell_type":"code","source":["class MaskedMultiAttentionHead(nn.Module):\n","  def __init__(self, config):\n","    super().__init__()\n","    embedding_dim = config.hidden_size\n","    num_head = config.num_attention_heads\n","    head_dim = embedding_dim // num_head\n","    self.attn_heads = nn.ModuleList(\n","        [MaskedAttentionHead(embedding_dim, head_dim) for _ in range(num_head)]\n","    )\n","    self.output_layer = nn.Linear(embedding_dim, embedding_dim)\n","\n","  def forward(self, hidden_state):\n","    maskedattn_outputs = torch.cat([h(hidden_state) for h in self.attn_heads], dim=-1)\n","    maskedattn_outputs = self.output_layer(maskedattn_outputs)\n","    return maskedattn_outputs"],"metadata":{"id":"OS-ZNNWUxwHx","executionInfo":{"status":"ok","timestamp":1697618253497,"user_tz":-540,"elapsed":4,"user":{"displayName":"원인호","userId":"14809865194257546197"}}},"execution_count":124,"outputs":[]},{"cell_type":"code","source":["masked_multi_attn = MaskedMultiAttentionHead(config)\n","attn_outputs = masked_multi_attn(embeddings)\n","attn_outputs.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"48tUKx210dGY","executionInfo":{"status":"ok","timestamp":1697618263911,"user_tz":-540,"elapsed":1053,"user":{"displayName":"원인호","userId":"14809865194257546197"}},"outputId":"620abdce-9fa5-4ca2-ac79-2cc40a82718f"},"execution_count":127,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 6, 768])"]},"metadata":{},"execution_count":127}]},{"cell_type":"code","source":["class EncoderDecoderAttentionHead(nn.Module):\n","  def __init__(self, embedding_dim, head_dim):\n","    super().__init__()\n","    self.q = nn.Linear(embedding_dim, head_dim)\n","    self.k = nn.Linear(embedding_dim, head_dim)\n","    self.v = nn.Linear(embedding_dim, head_dim)\n","\n","  def forward(self, encoder_hidden_state, decoder_hidden_state):\n","    attn_outputs = scaled_dot_product_attention(\n","        self.q(decoder_hidden_state), self.k(encoder_hidden_state), self.v(encoder_hidden_state)\n","    )\n","    return attn_outputs"],"metadata":{"id":"lj2wpta00tGW","executionInfo":{"status":"ok","timestamp":1697618794937,"user_tz":-540,"elapsed":997,"user":{"displayName":"원인호","userId":"14809865194257546197"}}},"execution_count":134,"outputs":[]},{"cell_type":"code","source":["class MultiEncoderDecoderAttentionHead(nn.Module):\n","  def __init__(self, config):\n","    super().__init__()\n","    embedding_dim = config.hidden_size\n","    num_head = config.num_attention_heads\n","    head_dim = embedding_dim // num_head\n","    self.attn_heads = nn.ModuleList(\n","        [EncoderDecoderAttentionHead(embedding_dim, head_dim) for _ in range(num_head)]\n","    )\n","    self.output_layer = nn.Linear(embedding_dim, embedding_dim)\n","\n","  def forward(self, encoder_hidden_state, decoder_hidden_state):\n","    attn_outputs = torch.cat([h(encoder_hidden_state, decoder_hidden_state) for h in self.attn_heads], dim=-1)\n","    attn_outputs = self.output_layer(attn_outputs)\n","    return attn_outputs"],"metadata":{"id":"DF_COWSf8h4O","executionInfo":{"status":"ok","timestamp":1697618794937,"user_tz":-540,"elapsed":6,"user":{"displayName":"원인호","userId":"14809865194257546197"}}},"execution_count":135,"outputs":[]},{"cell_type":"code","source":["multi_encoder_decoder_attn = MultiEncoderDecoderAttentionHead(config)\n","attn_outputs = multi_encoder_decoder_attn(attn_outputs, attn_outputs)\n","attn_outputs.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eQ700OIM9WWT","executionInfo":{"status":"ok","timestamp":1697618794937,"user_tz":-540,"elapsed":5,"user":{"displayName":"원인호","userId":"14809865194257546197"}},"outputId":"1d3ad9ab-9ad5-43fe-a36f-e757798caae0"},"execution_count":136,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 6, 768])"]},"metadata":{},"execution_count":136}]},{"cell_type":"code","source":["class FeedForward(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.linear_1 = nn.Linear(config.hidden_size, config.intermediate_size)\n","        self.linear_2 = nn.Linear(config.intermediate_size, config.hidden_size)\n","        self.gelu = nn.GELU()\n","        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","\n","    def forward(self, x):\n","        x = self.linear_1(x)\n","        x = self.gelu(x)\n","        x = self.linear_2(x)\n","        x = self.dropout(x)\n","        return x"],"metadata":{"id":"eucRRNLn9lu6","executionInfo":{"status":"ok","timestamp":1697618839160,"user_tz":-540,"elapsed":1480,"user":{"displayName":"원인호","userId":"14809865194257546197"}}},"execution_count":137,"outputs":[]},{"cell_type":"code","source":["class TransformerDecoderLayer(nn.Module):\n","  def __init__(self, config):\n","    super().__init__()\n","    self.layer_norm1 = nn.LayerNorm(config.hidden_size)\n","    self.layer_norm2 = nn.LayerNorm(config.hidden_size)\n","    self.layer_norm3 = nn.LayerNorm(config.hidden_size)\n","\n","    self.Maskedattention = MaskedMultiAttentionHead(config)\n","    self.EncoderDecoderattention = MultiEncoderDecoderAttentionHead(config)\n","\n","    self.feed_forward = FeedForward(config)\n","\n","  def forward(self, encoder_hidden_state, decoder_hidden_state):\n","    hidden_state1 = self.layer_norm1(decoder_hidden_state)\n","    masked_outputs = decoder_hidden_state + self.Maskedattention(hidden_state1)\n","\n","    hidden_state2 = self.layer_norm2(masked_outputs)\n","    final_hidden = masked_outputs + self.EncoderDecoderattention(encoder_hidden_state, hidden_state2)\n","\n","    final_hidden = final_hidden + self.feed_forward(self.layer_norm3(final_hidden))\n","    return final_hidden"],"metadata":{"id":"phLWa4OA97zO","executionInfo":{"status":"ok","timestamp":1697619540839,"user_tz":-540,"elapsed":532,"user":{"displayName":"원인호","userId":"14809865194257546197"}}},"execution_count":142,"outputs":[]},{"cell_type":"code","source":["class TransformerDecoder(nn.Module):\n","  def __init__(self, config):\n","    super().__init__()\n","    self.embeddings = DecoderEmbeddings(config)\n","\n","    num_layer = config.num_hidden_layers\n","    self.decoder_layer = nn.ModuleList(\n","        [TransformerDecoderLayer(config) for _ in range(num_layer)]\n","    )\n","\n","  def forward(self, encoder_final_hidden, y):\n","    y = self.embeddings(y)\n","    for d in self.decoder_layer :\n","      y = d(encoder_final_hidden, y)\n","    return y"],"metadata":{"id":"4GjMN0ox_emq","executionInfo":{"status":"ok","timestamp":1697619542411,"user_tz":-540,"elapsed":7,"user":{"displayName":"원인호","userId":"14809865194257546197"}}},"execution_count":143,"outputs":[]},{"cell_type":"code","source":["decoder = TransformerDecoder(config)"],"metadata":{"id":"EYqeshJ_AdCC","executionInfo":{"status":"ok","timestamp":1697619543710,"user_tz":-540,"elapsed":1304,"user":{"displayName":"원인호","userId":"14809865194257546197"}}},"execution_count":144,"outputs":[]},{"cell_type":"code","source":["decoder_output = decoder(attn_outputs, y)"],"metadata":{"id":"1Ef7SH5bAgQz","executionInfo":{"status":"ok","timestamp":1697619575960,"user_tz":-540,"elapsed":954,"user":{"displayName":"원인호","userId":"14809865194257546197"}}},"execution_count":147,"outputs":[]},{"cell_type":"code","source":["decoder_output.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YD-l7cXnArIw","executionInfo":{"status":"ok","timestamp":1697619584897,"user_tz":-540,"elapsed":852,"user":{"displayName":"원인호","userId":"14809865194257546197"}},"outputId":"18f27163-df26-4fb5-ad3a-081180c0b033"},"execution_count":148,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 6, 768])"]},"metadata":{},"execution_count":148}]}]}