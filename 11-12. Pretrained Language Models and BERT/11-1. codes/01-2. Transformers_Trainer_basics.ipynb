{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["ğŸ¤— ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜í›„ ëŸ°íƒ€ì„ ì¬ì‹œì‘ ğŸ¤—"],"metadata":{"id":"Ys8026gZQX-x"}},{"cell_type":"code","source":["!pip install transformers sentencepiece datasets accelerate -qqq"],"metadata":{"id":"SEPyGKhQ3jas"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.1.3. ğŸ¤— í—ˆë¸Œì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°"],"metadata":{"id":"_TFgeT78cTBA"}},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","# dataset = load_dataset('wikitext', 'wikitext-103-v1')\n"],"metadata":{"id":"TWC41JcTeq44"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3.2. ë°ì´í„° ì „ì²˜ë¦¬ : Dataset.map()"],"metadata":{"id":"bJsRnCeR0z3g"}},{"cell_type":"markdown","source":["### 3.2.1. Dataset.map() ê¸°ë³¸ ìš©ë²•"],"metadata":{"id":"oA7RTBoaetF_"}},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","dataset = load_dataset('imdb', split=\"train[:1000]\")\n","\n","\n"],"metadata":{"id":"XBwP3gRP03B6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset[0]['length']"],"metadata":{"id":"q9LxHJ83MHDM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(train_dataset[0]['text'])"],"metadata":{"id":"Evlta8R7MK2c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.2.2. í† í¬ë‚˜ì´ì € ì ìš©"],"metadata":{"id":"mIKnmnkGft3Z"}},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n"],"metadata":{"id":"J1pmdsG5geRP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.2.3. ë³‘ë ¬ ì²˜ë¦¬"],"metadata":{"id":"G4DJORnXg47K"}},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","def tokenize(examples):\n","    return tokenizer(examples[\"text\"], padding=True, max_length=50)\n","\n","tokenized_dataset = dataset.map(tokenize, batched=True)"],"metadata":{"id":"fsK0iR4zg7gs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. í›ˆë ¨ API (Trainer)"],"metadata":{"id":"3VqLvsLEhpFD"}},{"cell_type":"markdown","source":["## 4.2. Trainer API ì‚¬ìš© ì˜ˆì œ"],"metadata":{"id":"14BJlvDNhwwB"}},{"cell_type":"code","source":["from transformers import GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling\n","from transformers import Trainer, TrainingArguments\n","from datasets import load_dataset\n","\n","\n","# 1. ì‘ì—… ì •ì˜: ë¬¸ì¥ ìƒì„±\n","\n","# 2. í•™ìŠµ ë°ì´í„° ë¡œë”©\n","train_dataset = load_dataset('wikitext', 'wikitext-103-raw-v1', split='train[:1000]')\n","\n","\n","# 3. í† í¬ë‚˜ì´ì €ì™€ ëª¨ë¸ ë¡œë”©\n","\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","model = GPT2LMHeadModel.from_pretrained('gpt2')\n","\n","\n","# 4. í•™ìŠµ ë°ì´í„° ì „ì²˜ë¦¬\n","def tokenize_function(examples):\n","\toutput = tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n","\treturn output\n","\n","# map í•¨ìˆ˜ë¥¼ ì´ìš©í•œ í† í¬ë‚˜ì´ì§•\n","tokenized_datasets = train_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n","\n","# ë°ì´í„° ì½œë ˆì´í„° ì„¤ì •\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n","\n"],"metadata":{"id":"czKts-pBnlq8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 5. ëª¨ë¸ í•™ìŠµ\n","# í•™ìŠµì„ ìœ„í•œ ì„¤ì •\n","training_args = TrainingArguments(\n","\toutput_dir=\"./gpt2_finetuned\",\n","\toverwrite_output_dir=True,\n","\tnum_train_epochs=3,\n","\tper_device_train_batch_size=2,\n","\tsave_steps=1000,\n","\tsave_total_limit=2,\n",")\n","\n","# Trainer ê°ì²´ë¥¼ ìƒì„±\n","trainer = Trainer(\n","\tmodel=model,\n","\targs=training_args,\n","\tdata_collator=data_collator,\n","\ttrain_dataset=tokenized_datasets,\n",")\n","\n","# í•™ìŠµ ì‹œì‘\n","trainer.train()"],"metadata":{"id":"_sb0Nlz-oKWX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.3. DataCollator"],"metadata":{"id":"d1_qDzW5hzxn"}},{"cell_type":"markdown","source":["### DataCollatorForLanguageModeling"],"metadata":{"id":"cTusCWaDo5aL"}},{"cell_type":"code","source":["from transformers import DataCollatorForLanguageModeling\n","\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer, mlm=False\n",")"],"metadata":{"id":"5RFs7yJGo1lN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### DataCollatorForTokenClassification"],"metadata":{"id":"QaE2L-u2o9Q4"}},{"cell_type":"code","source":["from transformers import DataCollatorForTokenClassification\n","\n","data_collator = DataCollatorForTokenClassification(\n","    tokenizer=tokenizer\n",")"],"metadata":{"id":"ldNZFv3Fo4Y0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### DataCollatorWithPadding"],"metadata":{"id":"_aC3IIhJpAJB"}},{"cell_type":"code","source":["from transformers import DataCollatorWithPadding\n","\n","data_collator = DataCollatorWithPadding(\n","    tokenizer=tokenizer\n",")"],"metadata":{"id":"1u18uVwho_kg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### DataCollatorForSeq2Seq"],"metadata":{"id":"kO07gC9GpCXy"}},{"cell_type":"code","source":["from transformers import DataCollatorForSeq2Seq\n","\n","data_collator = DataCollatorForSeq2Seq(\n","    tokenizer=tokenizer\n",")"],"metadata":{"id":"d8OimlBTpB1U"},"execution_count":null,"outputs":[]}]}